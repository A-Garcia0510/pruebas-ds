# ğŸ§ª Sistema de Testing - CafÃ©-VT Loyalty

Este directorio contiene todos los tests del sistema de fidelizaciÃ³n CafÃ©-VT.

## ğŸ“ Estructura de Tests

```
tests/
â”œâ”€â”€ __init__.py                 # InicializaciÃ³n del mÃ³dulo
â”œâ”€â”€ conftest.py                 # ConfiguraciÃ³n de pytest
â”œâ”€â”€ test_loyalty_engine.py      # Tests unitarios del motor de scoring
â”œâ”€â”€ test_transactions.py        # Tests unitarios de transacciones
â”œâ”€â”€ test_api_endpoints.py       # Tests de integraciÃ³n de API
â”œâ”€â”€ test_user_flows.py          # Tests de flujos de usuario
â”œâ”€â”€ test_database_integration.py # Tests de integraciÃ³n con BD
â”œâ”€â”€ test_performance.py         # Tests de rendimiento
â””â”€â”€ README.md                   # Esta documentaciÃ³n
```

## ğŸ¯ Tipos de Tests

### 1. Tests Unitarios (`@pytest.mark.unit`)
- **PropÃ³sito**: Probar funciones individuales y mÃ©todos
- **Archivos**: `test_loyalty_engine.py`, `test_transactions.py`
- **Cobertura**: LÃ³gica de negocio, cÃ¡lculos, validaciones

### 2. Tests de IntegraciÃ³n (`@pytest.mark.integration`)
- **PropÃ³sito**: Probar interacciÃ³n entre componentes
- **Archivos**: `test_api_endpoints.py`, `test_database_integration.py`
- **Cobertura**: Endpoints API, base de datos, servicios

### 3. Tests de API (`@pytest.mark.api`)
- **PropÃ³sito**: Probar endpoints HTTP
- **Archivos**: `test_api_endpoints.py`
- **Cobertura**: Respuestas HTTP, cÃ³digos de estado, JSON

### 4. Tests de Base de Datos (`@pytest.mark.database`)
- **PropÃ³sito**: Probar operaciones de BD
- **Archivos**: `test_database_integration.py`
- **Cobertura**: Consultas, transacciones, constraints

### 5. Tests de Usuario (`@pytest.mark.user`)
- **PropÃ³sito**: Simular flujos reales de usuario
- **Archivos**: `test_user_flows.py`
- **Cobertura**: Casos de uso completos, experiencias de usuario

### 6. Tests de Rendimiento (`@pytest.mark.performance`)
- **PropÃ³sito**: Probar rendimiento y escalabilidad
- **Archivos**: `test_performance.py`
- **Cobertura**: Tiempo de respuesta, concurrencia, memoria

## ğŸš€ EjecuciÃ³n de Tests

### Ejecutar Todos los Tests
```bash
cd src/loyalty
python run_tests.py
```

### Ejecutar Tests EspecÃ­ficos

#### Tests Unitarios
```bash
python -m pytest tests/ -m unit -v
```

#### Tests de IntegraciÃ³n
```bash
python -m pytest tests/ -m integration -v
```

#### Tests de API
```bash
python -m pytest tests/ -m api -v
```

#### Tests de Base de Datos
```bash
python -m pytest tests/ -m database -v
```

#### Tests de Usuario
```bash
python -m pytest tests/ -m user -v
```

#### Tests de Rendimiento
```bash
python -m pytest tests/ -m performance -v
```

### Ejecutar Tests RÃ¡pidos (Sin Tests Lentos)
```bash
python -m pytest tests/ -m "not slow" -v
```

### Ejecutar Tests con Cobertura
```bash
python -m pytest tests/ --cov=services --cov=utils --cov-report=html
```

### Ejecutar Tests en Paralelo
```bash
python -m pytest tests/ -n auto
```

## ğŸ“Š Reportes

### Reporte de Cobertura
- **UbicaciÃ³n**: `htmlcov/index.html`
- **MÃ©tricas**: Porcentaje de cÃ³digo cubierto por tests

### Reporte HTML
- **UbicaciÃ³n**: `reports/test_report.html`
- **Contenido**: Resultados detallados de todos los tests

### Reporte en Consola
- **Formato**: Verbose con duraciÃ³n de tests
- **Marcadores**: Colores para diferentes tipos de tests

## ğŸ”§ ConfiguraciÃ³n

### pytest.ini
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --color=yes
    --durations=10
    --cov=services
    --cov=utils
    --cov-report=html:htmlcov
    --cov-report=term-missing
```

### Marcadores Personalizados
- `@pytest.mark.unit` - Tests unitarios
- `@pytest.mark.integration` - Tests de integraciÃ³n
- `@pytest.mark.api` - Tests de API
- `@pytest.mark.database` - Tests de base de datos
- `@pytest.mark.user` - Tests de usuario
- `@pytest.mark.performance` - Tests de rendimiento
- `@pytest.mark.slow` - Tests lentos
- `@pytest.mark.smoke` - Tests de humo
- `@pytest.mark.regression` - Tests de regresiÃ³n

## ğŸ¯ Casos de Prueba Cubiertos

### Motor de Scoring
- âœ… CÃ¡lculo de score por frecuencia
- âœ… CÃ¡lculo de score por monto
- âœ… CÃ¡lculo de score por recencia
- âœ… CÃ¡lculo de score por variedad
- âœ… CÃ¡lculo de score por referidos
- âœ… AsignaciÃ³n de niveles
- âœ… Progreso al siguiente nivel

### Transacciones
- âœ… Registro de transacciones vÃ¡lidas
- âœ… ValidaciÃ³n de datos de entrada
- âœ… CÃ¡lculo de puntos por compra
- âœ… AplicaciÃ³n de multiplicadores por nivel
- âœ… Historial de transacciones
- âœ… AuditorÃ­a de transacciones

### API Endpoints
- âœ… GET /api/v1/loyalty/profile/{user_id}
- âœ… POST /api/v1/loyalty/earn-points
- âœ… POST /api/v1/loyalty/redeem-reward
- âœ… GET /api/v1/loyalty/rewards
- âœ… POST /api/v1/loyalty/referral
- âœ… POST /api/v1/loyalty/use-referral
- âœ… GET /api/v1/loyalty/transactions/{user_id}
- âœ… POST /api/v1/loyalty/check-tier-upgrade

### Flujos de Usuario
- âœ… Registro completo de usuario
- âœ… Compra y ganancia de puntos
- âœ… Subida de nivel
- âœ… Canje de recompensas
- âœ… Sistema de referidos
- âœ… ExpiraciÃ³n de puntos
- âœ… CampaÃ±as de marketing
- âœ… Analytics e insights

### Base de Datos
- âœ… ConexiÃ³n y configuraciÃ³n
- âœ… Operaciones CRUD
- âœ… Transacciones y rollback
- âœ… Manejo de errores
- âœ… Pool de conexiones

### Rendimiento
- âœ… Tiempo de respuesta < 200ms
- âœ… Carga con 1000+ usuarios
- âœ… Concurrencia de operaciones
- âœ… Uso de memoria < 100MB
- âœ… CachÃ© y optimizaciones

## ğŸ› Debugging

### Ejecutar Tests con Debug
```bash
python -m pytest tests/ -s -v --pdb
```

### Ejecutar Test EspecÃ­fico
```bash
python -m pytest tests/test_loyalty_engine.py::TestLoyaltyEngine::test_calculate_user_score -v
```

### Ver Cobertura Detallada
```bash
python -m pytest tests/ --cov=services --cov-report=term-missing
```

## ğŸ“ˆ MÃ©tricas de Calidad

### Cobertura Objetivo
- **Cobertura Total**: > 90%
- **Cobertura de Servicios**: > 95%
- **Cobertura de Utils**: > 90%

### Rendimiento Objetivo
- **Tests Unitarios**: < 1 segundo
- **Tests de IntegraciÃ³n**: < 5 segundos
- **Tests de Rendimiento**: < 10 segundos
- **Tiempo Total**: < 30 segundos

### Confiabilidad
- **Tests Pasando**: 100%
- **Tests Estables**: > 99%
- **Falsos Positivos**: < 1%

## ğŸ”„ CI/CD Integration

### GitHub Actions
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-html
      - name: Run tests
        run: |
          cd src/loyalty
          python run_tests.py
```

## ğŸ“ Mejores PrÃ¡cticas

### Escribir Tests
1. **Nombres Descriptivos**: `test_calculate_user_score_with_high_frequency`
2. **Arrange-Act-Assert**: Estructura clara de tests
3. **Mocks Apropiados**: Mockear dependencias externas
4. **Datos de Prueba**: Usar fixtures y datos realistas
5. **Assertions EspecÃ­ficos**: Verificar comportamiento exacto

### Mantener Tests
1. **Actualizar con Cambios**: Mantener tests sincronizados
2. **Refactorizar Tests**: Eliminar duplicaciÃ³n
3. **Optimizar Rendimiento**: Tests rÃ¡pidos y eficientes
4. **Documentar Casos**: Comentarios para casos complejos

## ğŸ†˜ Troubleshooting

### Problemas Comunes

#### Tests Faltan
```bash
# Verificar instalaciÃ³n de pytest
pip install pytest pytest-asyncio

# Verificar marcadores
python -m pytest --markers
```

#### Tests Lentos
```bash
# Ejecutar solo tests rÃ¡pidos
python -m pytest tests/ -m "not slow"

# Ver duraciÃ³n de tests
python -m pytest tests/ --durations=10
```

#### Errores de Base de Datos
```bash
# Verificar configuraciÃ³n de BD
python -c "from utils.database import get_db; print('DB OK')"

# Ejecutar tests sin BD
python -m pytest tests/ -m "not database"
```

## ğŸ“ Soporte

Para problemas con tests:
1. Revisar logs de ejecuciÃ³n
2. Verificar configuraciÃ³n de pytest
3. Consultar documentaciÃ³n de pytest
4. Revisar issues del proyecto

---

**Ãšltima actualizaciÃ³n**: Diciembre 2024
**VersiÃ³n**: 1.0
**Responsable**: Equipo de Testing 